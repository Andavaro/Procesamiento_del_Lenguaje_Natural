# Procesamiento_del_Lenguaje_Natural

El procesamiento de lenguaje natural, abreviado NLP por sus siglas en inglés (natural language processing), es un campo de las ciencias de la computación, de la inteligencia artificial y de la lingüística que estudia las interacciones entre las computadoras y el lenguaje humano.

En este repositorio están contenidos los desafíos planteados en el curso de NLP de la Especialización en Inteligencia Artificial de la Universidad de Buenos Aires. A continuación se describen brevemente los 6 desafíos contenidos en el repositorio:

## [Desafío 1](https://github.com/Andavaro/Procesamiento_del_Lenguaje_Natural/blob/main/1a%20-%20word2vec.ipynb)
> En este desafío se crearon las funciones correspondientes a los conceptos básicos de NLP: obtener el vocabulario, hacer One Hot Encoding, generar los vectores de frecuencia, generar la matriz TF-IDF y calcular la similitud coseno entre documentos.

## [Desafío 2](https://github.com/Andavaro/Procesamiento_del_Lenguaje_Natural/blob/main/2b_bot_dnn_spacy_esp.ipynb)
> Se programó un bot basado en reglas con DNN + Spacy. Es un bot sencillo pensado para una tienda genérica con preguntas echas frecuentemente por los clientes, tales como: solicitar datos de contacto, pedir ayuda con alguna compra, preguntar precios y disponibilidad, métodos de envío, etc. Se verificó su desempeño simulando una conversación con un cliente, con resultados favorables.

## [Desafío 3](https://github.com/Andavaro/Procesamiento_del_Lenguaje_Natural/blob/main/3b_Custom_embedding_con_Gensim.ipynb)
> Se utilizó el libro 'La vuelta al mundo en 80 días', del autor Julio Verne, como dataset para crear custom embeddings con Gensim. Se entrenó el modelo generador de vectores y se verificó que el funcionamiento era aceptable.

## [Desafío 4](https://github.com/Andavaro/Procesamiento_del_Lenguaje_Natural/blob/main/4d%20-%20prediccio%CC%81n_palabra.ipynb)
> Se iutilizaron como dataset las canciones de Nirvana para entrenar el modelo de próxima palabra. El desempeño no fue el esperado y se presentó overfiting, pero se obtuvo mejores resultados que al usar el libro del desafío anterior como dataset.

## [Desafío 5](https://github.com/Andavaro/Procesamiento_del_Lenguaje_Natural/blob/main/5_clothing_ecommerce_reviews.ipynb)
> Se entrenó un modelo con embeddings + LSTM para categorizar reseñas. 

## [Desafío 6](https://github.com/Andavaro/Procesamiento_del_Lenguaje_Natural/blob/main/6_QAbot.ipynb)
> Se usó un esquema encoder-decoder para construir un BOT que responda preguntas de un usuario.
